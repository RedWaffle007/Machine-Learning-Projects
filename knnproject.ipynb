{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edc18bd-4d75-4303-8c10-f6235327dc28",
   "metadata": {},
   "source": [
    "TRAINING A KNN MODEL FOR THE IMDB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3143fee5-46c1-4728-8d4c-7de70c012450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting data from zipped file and reading it\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "#specifying file_path\n",
    "file_path = 'Dataset.tar.gz'\n",
    "\n",
    "# Open and extract the .tar.gz file\n",
    "with tarfile.open(file_path, 'r:gz') as tar:\n",
    "    tar.extractall(path=\"extracted_files\")  # Extract files to the directory\n",
    "\n",
    "# Check the contents of the extracted folder\n",
    "extracted_files = os.listdir(\"extracted_files/aclImdb\")\n",
    "print(extracted_files[:10])  # Prints only the first 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0c6c4-3adc-4099-93b0-ebe3863ee4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the training dataset into a pandas dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to read reviews and labels from a directory\n",
    "def load_data(directory, label):\n",
    "    reviews = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            reviews.append(file.read())\n",
    "    return pd.DataFrame({'review': reviews, 'sentiment': label})\n",
    "\n",
    "# Load positive and negative reviews for training\n",
    "train_pos = load_data('extracted_files/aclImdb/train/pos', label=1)\n",
    "train_neg = load_data('extracted_files/aclImdb/train/neg', label=0)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "train_df = pd.concat([train_pos, train_neg], ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaaf6da-6dfa-4224-837f-17c11edf0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the training dataset\n",
    "train_df = train_df.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf905693-e901-421d-a0f3-4f20e430c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the test dataset into a pandas dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to read reviews and labels from a directory\n",
    "def load_data(directory, label):\n",
    "    reviews = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            reviews.append(file.read())\n",
    "    return pd.DataFrame({'review': reviews, 'sentiment': label})\n",
    "\n",
    "# Load positive and negative reviews for training\n",
    "test_pos = load_data('extracted_files/aclImdb/test/pos', label=1)\n",
    "test_neg = load_data('extracted_files/aclImdb/test/neg', label=0)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "test_df = pd.concat([test_pos, test_neg], ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a837ec2-b8aa-4f24-a8e7-c6100d604e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling test dataset\n",
    "test_df = test_df.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976231f5-c0c1-4b73-9e68-544b86a03e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA on Training dataset\n",
    "#checking the distributions\n",
    "train_df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077df98-872e-4f9d-b2b5-43443a118b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing values\n",
    "print(train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add0a94d-6416-4377-84be-e4e73e5d5d77",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING AND TOKENIZATION, LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58edb3-4e8d-43b7-a247-f7f60c1b317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "#load english model for spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#get the stop words list from spacy\n",
    "stop_words = list(STOP_WORDS)\n",
    "\n",
    "#words to exclude from stop_words\n",
    "excluding = ['against', 'not', 'don', \"don't\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
    "             'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", \n",
    "             'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n",
    "             'needn', \"needn't\",'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
    "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "#final stop_words list\n",
    "final_stop_words = [word for word in stop_words if word not in excluding]\n",
    "\n",
    "#initialzing the stemmer\n",
    "snow = SnowballStemmer('english')\n",
    "\n",
    "#function for processing the text\n",
    "def process_text(texts):\n",
    "    final_text_list = []\n",
    "\n",
    "    for sent in texts:\n",
    "        #set sent to empty if not a string\n",
    "        if not isinstance(sent,str):\n",
    "            final_text_list.append(\"\")\n",
    "            continue\n",
    "\n",
    "        #basic processing steps before tokenization\n",
    "        sent = sent.lower().strip()\n",
    "        sent = re.sub(r'\\s+', ' ', sent) # Multiple spaces and tabs into one\n",
    "        sent = re.sub('<.*?>', '', sent) #remove html tags\n",
    "\n",
    "        #applying spacy nlp pipeline to sent\n",
    "        doc = nlp(sent)\n",
    "\n",
    "        filtered_sentence = []\n",
    "\n",
    "        for token in doc:\n",
    "            if len(token.text)>2 and token.text not in final_stop_words and not token.is_digit:\n",
    "                filtered_sentence.append(snow.stem(token.text))\n",
    "\n",
    "        #join final string of cleaned sentences\n",
    "        final_list = \" \".join(filtered_sentence)\n",
    "        final_text_list.append(final_list)\n",
    "\n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29adcb-e1ca-4cc9-ada8-0407c8f2aba7",
   "metadata": {},
   "source": [
    "Train - validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c248d-e7da-4be1-9a57-6cc0756466f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting training dataset into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_df[\"review\"],\n",
    "                                                 train_df[\"sentiment\"],\n",
    "                                                 test_size = 0.10,\n",
    "                                                 shuffle = True,\n",
    "                                                 random_state = 324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12471a-3e24-44e1-b857-d24cb3cd1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the datatype of x_train\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c107a94-4bd7-411d-b84c-17fefa969b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.head())  # Print the first few rows\n",
    "print(x_train.index)  # Print index if it's Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc70254-31ca-4889-ad58-b61901f1f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function to process the columns\n",
    "print(\"processing the review column\")\n",
    "x_train = process_text(x_train.tolist())\n",
    "x_val = process_text(x_val.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4d0c3-2ac1-4086-bfca-7c9f4cf4f03c",
   "metadata": {},
   "source": [
    "Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14ce44-c2f1-4b27-a258-f041a7e3619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#######PIPELINE########\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('text_vect', CountVectorizer(binary = True,\n",
    "                                 max_features = 15)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "#display pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display = 'diagram')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079fb1e-8042-432a-9561-9086a4c46435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[ :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6055781-e228-42c3-9d1d-928ada72c42b",
   "metadata": {},
   "source": [
    "Fit The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27215e5-cd57-4b79-9d24-2cd02539bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(x_train, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e584c-4135-4f81-825e-3feadfab2a7c",
   "metadata": {},
   "source": [
    "Test the classifier on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e77ec-775a-492f-a8a0-d0b0ac9bf713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,  classification_report, accuracy_score\n",
    "\n",
    "#predicting on validation set\n",
    "pred_values = pipeline.predict(x_val)\n",
    "\n",
    "print(confusion_matrix(y_val.values, pred_values))\n",
    "print(classification_report(y_val.values, pred_values))\n",
    "print('Accuracy score:', accuracy_score(y_val.values, pred_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d3805-3c7c-4e3e-92ba-30e83b836dcc",
   "metadata": {},
   "source": [
    "Tuning the model using RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f773fe-23a8-4609-8ba1-e22b179f9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "import numpy as np\n",
    "\n",
    "#parameteres distributions\n",
    "param_distributions = {\n",
    "    'knn__n_neighbors': np.arange(3, 20, 2), #odd values for neighbors\n",
    "    'knn__weights': ['uniform', 'distance'], #weighting methods\n",
    "    'knn__metric': ['minkowski', 'euclidean', 'manhattan'] #distance methods\n",
    "}\n",
    "\n",
    "#initializing the randomsearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions,\n",
    "    n_iter = 20, #no. of random combinations to try\n",
    "    n_jobs = -1,\n",
    "    random_state = 42,\n",
    "    cv = 5, #5 fold cross validation\n",
    "    scoring = 'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26d20b-ea3a-41dd-a0b1-b5ec9810a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the random_serach\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c108b2-9f3f-4e44-8ca5-6f9ca797b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the best parameters\n",
    "print('Best parameters found:', random_search.best_params_)\n",
    "\n",
    "#use the best model\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5cad2-63c8-4cc4-9893-0b4b1e4af9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions with val set with best model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "pred_values = best_model.predict(x_val)\n",
    "\n",
    "print(confusion_matrix(y_val.values, pred_values))\n",
    "print(classification_report(y_val.values, pred_values))\n",
    "print('Accuracy_score:', accuracy_score(y_val.values, pred_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc0fbe-7048-40e7-bb17-6c03b1756b74",
   "metadata": {},
   "source": [
    "Using the knn model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a355d-22f7-45ba-9989-971b1df4022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee3be8-0241-4319-a796-ed3036937194",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = process_text(test_df[\"review\"].tolist())\n",
    "y_test = test_df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b16572-dc01-4099-963f-a2e85974bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test[ :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df631f59-7e3e-48cc-afe2-6d4a56a42c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the best model on test data\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "test_predictions = best_model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print('Accuracy_score:', accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfd1f9-ae50-4727-bebf-f89bcd11db10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
